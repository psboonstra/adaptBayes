% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glm_sab.R
\name{glm_sab}
\alias{glm_sab}
\title{Fit GLM with the 'sensible adaptive bayes' prior}
\usage{
glm_sab(
  stan_fit = stanmodels$SAB_Stable,
  y,
  x_standardized,
  alpha_prior_mean,
  alpha_prior_cov,
  aug_projection,
  phi_mean,
  phi_sd,
  beta_orig_scale,
  beta_aug_scale,
  local_dof = 1,
  global_dof = 1,
  slab_precision = (1/15)^2,
  only_prior = F,
  mc_warmup = 50,
  mc_iter_after_warmup = 50,
  mc_chains = 1,
  mc_thin = 1,
  mc_stepsize = 0.1,
  mc_adapt_delta = 0.9,
  mc_max_treedepth = 15,
  ntries = 1,
  return_as_stanfit = FALSE,
  eigendecomp_hist_var = NULL,
  scale_to_variance225 = NULL
)
}
\arguments{
\item{stan_fit}{an R object of class stanfit, which allows the function to run
without recompiling the stan code.}

\item{y}{(vector) outcomes corresponding to the type of glm desired. This should
match whatever datatype is expected by the stan program.}

\item{x_standardized}{(matrix) matrix of numeric values with number of rows equal
to the length of y and number of columns equal to p+q. It is assumed without
verification that each column is standardized to whatever scale the prior
expects - in Boonstra and Barbaro, all predictors are marginally generated to have
mean zero and unit variance, so no standardization is conducted. In practice,
all data should be standardized to have a common scale before model fitting.
If regression coefficients on the natural scale are desired, they can be easily obtained
through unstandardizing.}

\item{alpha_prior_mean}{(vector) p-length vector giving the mean of alpha from the
historical analysis, corresponds to m_alpha in Boonstra and Barbaro}

\item{alpha_prior_cov}{(matrix) pxp positive definite matrix giving the variance of
alpha from the historical analysis, corresponds to S_alpha in Boonstra and Barbaro}

\item{aug_projection}{(matrix) pxq matrix that approximately projects the regression coefficients of
the augmented predictors onto the space of the regression coefficients for the original
predictors.This is the matrix P in the notation of Boonstra and Barbaro.
It can be calculated using the function 'create_projection'}

\item{phi_mean}{(real) mean of phi corresponding to a truncated normal distribution.
Since the support of the distribution is truncated to [0,1], it would make sense,
but is not required, that 'phi_mean' itself also be in [0,1]}

\item{beta_aug_scale}{(pos. real) constants indicating the prior scale of the
horseshoe. Both values correspond to 'c' in the notation of Boonstra and Barbaro,
because that paper never considers beta_orig_scale!=beta_aug_scale}

\item{local_dof}{(pos. integer) numbers indicating the degrees of freedom for
lambda_j and tau, respectively. Boonstra, et al. never considered local_dof != 1
or global_dof != 1.}

\item{global_dof}{(pos. integer) numbers indicating the degrees of freedom for
lambda_j and tau, respectively. Boonstra, et al. never considered local_dof != 1
or global_dof != 1.}

\item{slab_precision}{(pos. real) the slab-part of the regularized horseshoe,
this is equivalent to (1/d)^2 in the notation of Boonstra and Barbaro}

\item{only_prior}{(logical) should all data be ignored, sampling only from the prior?}

\item{mc_warmup}{number of MCMC warm-up iterations}

\item{mc_iter_after_warmup}{number of MCMC iterations after warm-up}

\item{mc_chains}{number of MCMC chains}

\item{mc_thin}{every nth draw to keep}

\item{mc_stepsize}{positive stepsize}

\item{mc_adapt_delta}{between 0 and 1}

\item{mc_max_treedepth}{max tree depth}

\item{ntries}{(pos. integer) the stan function will run up to this many times,
stopping either when the number of divergent transitions* is zero or when ntries
has been reached. The reported fit will be that with the fewest number of divergent iterations.}

\item{return_as_stanfit}{(logical) should the function return the stanfit
object asis or should a summary of stanfit be returned as a regular list}

\item{eigendecomp_hist_var:}{R object of class 'eigen' containing a pxp matrix
of eigenvectors in each row (equivalent to v_0 in Boonstra and Barbaro) and
a p-length vector of eigenvalues. This is by default equal to eigen(alpha_prior_cov)}

\item{scale_to_variance225:}{a vector assumed to be such that, when multiplied
by the diagonal elements of alpha_prior_cov, the result is a vector of
elements each equal to 225. This is explicitly calculated if it is not provided}
}
\value{
\code{list} object containing the draws and other information.
}
\description{
Program for fitting a GLM equipped with the 'sensible adaptive bayes' prior
evaluated in the manuscript.
}
\examples{

data(current)

alpha_prior_cov = matrix(data = c(0.02936, -0.02078, 0.00216, -0.00637,
                                  -0.02078, 0.03192, -0.01029, 0.00500,
                                  0.00216, -0.01029, 0.01991, -0.00428,
                                  -0.00637, 0.00500, -0.00428, 0.01650),
                         byrow = FALSE, nrow = 4);

scale_to_variance225 = diag(alpha_prior_cov) / 225;
eigendecomp_hist_var = eigen(alpha_prior_cov);
aug_projection1 = matrix(data = c(0.0608, -0.02628, -0.0488, 0.0484, 0.449, -0.0201,
                                  0.5695, -0.00855, 0.3877, 0.0729, 0.193, 0.4229,
                                  0.1816, 0.37240, 0.1107, 0.1081, -0.114, 0.3704,
                                  0.1209, 0.03683, -0.1517, 0.2178, 0.344, -0.1427),
                         byrow = TRUE, nrow = 4);

foo = glm_sab(y = current$y_curr,
              x_standardized = current[,2:11],
              alpha_prior_mean = c(1.462, -1.660, 0.769, -0.756),
              alpha_prior_cov = alpha_prior_cov,
              aug_projection = aug_projection1,
              phi_mean = 1,
              phi_sd = 0.25,
              beta_orig_scale = 0.0223,
              beta_aug_scale = 0.0223,
              local_dof = 1,
              global_dof = 1,
              slab_precision = 0.00444,
              only_prior = 0,
              mc_warmup = 1000,
              mc_iter_after_warmup = 1000,
              mc_chains = 2,
              mc_thin = 1,
              mc_stepsize = 0.1,
              mc_adapt_delta = 0.999,
              mc_max_treedepth = 15,
              ntries = 2,
              eigendecomp_hist_var = eigendecomp_hist_var,
              scale_to_variance225 = scale_to_variance225);

}
