% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glm_standard.R
\name{glm_standard}
\alias{glm_standard}
\title{GLM equipped with the 'standard' prior evaluated}
\usage{
glm_standard(
  stan_fit = stanmodels$RegHS_Stable,
  y,
  x_standardized,
  p,
  q,
  beta_orig_scale,
  beta_aug_scale,
  local_dof = 1,
  global_dof = 1,
  slab_precision = (1/15)^2,
  intercept_offset = NULL,
  only_prior = F,
  mc_warmup = 50,
  mc_iter_after_warmup = 50,
  mc_chains = 1,
  mc_thin = 1,
  mc_stepsize = 0.1,
  mc_adapt_delta = 0.9,
  mc_max_treedepth = 15,
  ntries = 1,
  return_as_stanfit = FALSE
)
}
\arguments{
\item{stan_fit}{an R object of class stanfit, which allows the function to run
without recompiling the stan code.}

\item{y}{(vector) outcomes corresponding to the type of glm desired. This should
match whatever datatype is expected by the stan program.}

\item{x_standardized}{(matrix) matrix of numeric values with number of rows equal
to the length of y and number of columns equal to p+q. It is assumed without
verification that each column is standardized to whatever scale the prior
expects - in Boonstra and Barbaro, all predictors are marginally generated to have
mean zero and unit variance, so no standardization is conducted. In practice,
all data should be standardized to have a common scale before model fitting.
If regression coefficients on the natural scale are desired, they be easily obtained
through unstandardizing.}

\item{q}{(nonneg. integers) numbers, the sum of which add up to the number of columns
in x_standardized. For the standard prior, this distinction is only needed if a different
constant scale parameter (beta_orig_scale, beta_aug_scale), which is the constant 'c'
in the notation of Boonstra and Barbaro, is used.}

\item{beta_aug_scale}{(pos. real) constants indicating the prior scale of the
horseshoe. Both values correspond to 'c' in the notation of Boonstra and Barbaro,
because that paper never considers beta_orig_scale!=beta_aug_scale}

\item{local_dof}{(pos. integer) numbers indicating the degrees of freedom for
lambda_j and tau, respectively. Boonstra, et al. never considered local_dof != 1
or global_dof != 1.}

\item{global_dof}{(pos. integer) numbers indicating the degrees of freedom for
lambda_j and tau, respectively. Boonstra, et al. never considered local_dof != 1
or global_dof != 1.}

\item{slab_precision}{(pos. real) the slab-part of the regularized horseshoe,
this is equivalent to (1/d)^2 in the notation of Boonstra and Barbaro}

\item{intercept_offset}{(vector) vector of 0's and 1's equal having the same length as y.
Those observations with a value of 1 have an additional constant offset in their linear
predictor, effectively a different intercept. This is useful to jointly regress
two datasets in which it is believed that the regression coefficients are the same
but not the intercepts and could be useful (but was not used) in the simulation study
to compare to a benchmark, namely if both the historical and current datasets
were available but there is a desire to adjust for potentially different baseline prevalences.}

\item{only_prior}{(logical) should all data be ignored, sampling only from the prior?}

\item{mc_warmup}{number of MCMC warm-up iterations}

\item{mc_iter_after_warmup}{number of MCMC iterations after warm-up}

\item{mc_chains}{number of MCMC chains}

\item{mc_thin}{every nth draw to keep}

\item{mc_stepsize}{positive stepsize}

\item{mc_adapt_delta}{between 0 and 1}

\item{mc_max_treedepth}{max tree depth}

\item{ntries}{(pos. integer) the stan function will run up to this many times,
stopping either when the number of divergent transitions* is zero or when ntries
has been reached. The reported fit will be that with the fewest number of divergent iterations.}

\item{return_as_stanfit}{(logical) should the function return the stanfit
object asis or should a summary of stanfit be returned as a regular list}
}
\value{
\code{list} object containing the draws and other information.
}
\description{
Program for fitting a GLM equipped with the 'standard' prior evaluated
in Boonstra and Barbaro, which is the regularized horseshoe.
}
